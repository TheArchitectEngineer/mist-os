# Copyright 2021 The Fuchsia Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

""" Generates BUILD.bazel rules for items in the Fuchsia SDK. """

# Disable Python formatting, see below why.
# fmt: off
# pyformat: disable

# NOTE: This file can be run either as Starlark (from a Bazel repository rule)
# or as Python (from a Bazel action). Do not use any statement or types that cannot
# run in both languages. This includes Bazel load() statements, the global 'json'
# module, or the Label type.
#
# Being able to run this file as Python helps build the Fuchsia Bazel SDK
# without using a Bazel workspace.
#
# The Python environment will mock the types of Bazel-specific values, such as
# Path, Label, struct, repository_ctx with custom classes that will expose the
# same API as their Starlark counterpart. However, referencing these types before
# they are defined is not possible.
#
# To make this possible, a special 'runtime' object must be passed by the caller
# to the functions exposed here. It models the current repository context and
# runtime environment. This must be a read-only Starlark struct, or Python class
# with the following fields/properties:
#
#  - runtime.ctx: repository_ctx
#
#    A repository_ctx value for the current repository rule. In the Python
#    environment, this must be an instance of a class that mimics the behavior
#    of the Bazel repository_ctx type.
#
#  - runtime.make_struct: Callable[struct, [**kwargs]]
#
#    A function that creates a new "struct" value in Starlark, or an instance
#    of an equivalent class in Python.
#
#  - runtime.fail: Callable[None, [str]]
#
#    A function that prints a fatal error message and terminates the current
#    execution. Similar to Starlark 'fail' function.
#
#  - runtime.workspace_path: Callable[Path, [str]]
#
#    A function that can convert a local path relative to the main workspace directory
#    and return its absolute Path value. As a special case, if the path starts with @,
#    it must point to a file in the repository, and the function will return
#    its parent directory Path value.
#
#  - runtime.label_to_path: Callable[Path, [str]]
#
#    A function that converts a Bazel label string, and converts it into
#    the equivalent Path value. Equivalent to ctx.path(Label(label)) in Starlark.
#
#  - runtime.json_decode: Callable[Any, [str]]
#
#    A function used to decode a JSON string into the corresponding Starlark or
#    Python value (usually a dict or a list).
#
#  - runtime.value_is_list: Callable[bool, [Any]]
#  - runtime.value_is_dict: Callable[bool, [Any]]
#  - runtime.value_is_struct: Callable[bool, [Any]]
#
#    A function that returns True if the input argument is a list, dict or struct
#    value, respectively.
#
#  - runtime.file_copier: Callable[None, [repository_ctx, Dict[str, List[str]]
#
#    A function that takes as input a dictionary, whose keys are paths to root
#    IDK directories, and whose values are list of file paths relative to the key.
#    For each (root_dir, file_paths) item, all files will be copied (or symlinked)
#    from their source location to the corresponding location in the destination
#    repository directory.
#
#  - runtime.find_repository_files_by_name: Callable[List[str], [str]]
#
#    A function that takes a file name (e.g. "BUILD.bazel") and find all instances present
#    in the current repository directory. This returns a list of relative file path strings.
#
#  - runtime.run_buildifier: Callable[bool, [List[str]]]
#
#    An optional function used to run the 'buildifier' tool over the generated
#    repository, to fix and verify its formatting. This must take a list of strings
#    which will be passed as command-line arguments to the tool. This must return True
#    on success, or False on failure.
#

def _header():
    return """# Copyright 2024 The Fuchsia Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

# DO NOT EDIT: GENERATED BY _generate_sdk_build_rules

package(default_visibility = ["//visibility:public"])

# Needed for @fuchsia_sdk//:all_files.
filegroup(
    name = "_EXPORT_SUBPACKAGE_FILEGROUP",
    srcs = glob(["**/*"]),
    visibility = ["//:__pkg__"],
)

"""

_SDK_TEMPLATES = {
    "api_version": "//fuchsia/workspace/sdk_templates:api_version_template.bzl",
    "api_level_constraint": "//fuchsia/workspace/sdk_templates:api_level_constraint.template",
    "api_level_flag": "//fuchsia/workspace/sdk_templates:api_level_flags.template",
    "bind_library": "//fuchsia/workspace/sdk_templates:bind_library.BUILD.template",
    "cc_library": "//fuchsia/workspace/sdk_templates:cc_library.BUILD.template",
    "cc_prebuilt_library": "//fuchsia/workspace/sdk_templates:cc_prebuilt_library.BUILD.template",
    "cc_prebuilt_library_linklib": "//fuchsia/workspace/sdk_templates:cc_prebuilt_library_linklib_sub.BUILD.template",
    "cc_prebuilt_library_distlib": "//fuchsia/workspace/sdk_templates:cc_prebuilt_library_distlib_sub.BUILD.template",
    "companion_host_tool": "//fuchsia/workspace/sdk_templates:companion_host_tool.BUILD.template",
    "component_manifest": "//fuchsia/workspace/sdk_templates:component_manifest.BUILD.template",
    "component_manifest_collection": "//fuchsia/workspace/sdk_templates:component_manifest_collection.BUILD.template",
    "export_all_files": "//fuchsia/workspace/sdk_templates:export_all_files.BUILD.template",
    "ffx_subtool": "//fuchsia/workspace/sdk_templates:ffx_subtool.BUILD.template",
    "ffx_subtool_external": "//fuchsia/workspace/sdk_templates:ffx_subtool_external.BUILD.template",
    "fidl_library": "//fuchsia/workspace/sdk_templates:fidl_library.BUILD.template",
    "filegroup": "//fuchsia/workspace/sdk_templates:filegroup.BUILD.template",
    "host_tool": "//fuchsia/workspace/sdk_templates:host_tool.BUILD.template",
    "host_tool_external": "//fuchsia/workspace/sdk_templates:host_tool_external.BUILD.template",
    "loadable_module": "//fuchsia/workspace/sdk_templates:loadable_module.BUILD.template",
    "loadable_module_sub": "//fuchsia/workspace/sdk_templates:loadable_module_sub.BUILD.template",
    "package": "//fuchsia/workspace/sdk_templates:package.BUILD.template",
    "prebuilt_lacewing_test": "//fuchsia/workspace/sdk_templates:prebuilt_lacewing_test.BUILD.template",
    "repository": "//fuchsia/workspace/sdk_templates:repository.BUILD.template",
    "select_alias": "//fuchsia/workspace/sdk_templates:select_alias.BUILD.template",
    "sysroot": "//fuchsia/workspace/sdk_templates:sysroot.BUILD.template",
    "sysroot_arch_sub": "//fuchsia/workspace/sdk_templates:sysroot_arch_sub.BUILD.template",
}

# Location of template for the top-level BUILD.bazel file in the final repository directory.
# Note that while this is expanded once, then the content of the resulting file is modified
# multiple times after that by various functions in this script.
_REPOSITORY_BUILD_TEMPLATE = (
    "//fuchsia/workspace/sdk_templates:fuchsia_sdk.BUILD.bazel"
)

# The following keys are used to add additional visibility restrictions that the
# caller can define. They are defined here for reference purposes.
HLCPP_VISIBILITY_KEY = "hlcpp"  # Used to restrict access to hlcpp targets.

def resolve_repository_labels(runtime):
    """Resolve the labels used by this repository.

    Call this early in the repository_rule() to avoid unexpected restarts when
    _generate_sdk_build_rules() is called.

    Args:
       runtime: A runtime value.
    """
    runtime.label_to_path(_REPOSITORY_BUILD_TEMPLATE)
    for template in _SDK_TEMPLATES.values():
        runtime.label_to_path(template)

def _is_external_file(filepath):
    """Returns true if |filepath| is a label to an external repository."""

    # fuchsia_idk_repository() ensures that all labels start with @<repo_name>//
    # so just checking the first character is enough.
    return filepath.startswith("@")

def _final_bazel_path(path):
    """Convert a path that appears in a metadata file into a corresponding Bazel label."""
    if _is_external_file(path):
        return path  # Already a label
    return "//:" + path

def _sdk_template_path(runtime, name):
    """Return the path value of a given SDK template file.

    The returned file path is always recorded as a repository input, thus
    any change to it will trigger a re-run of the repository implementation
    function.

    Args:
       runtime: A runtime value.
       name: A name for the template file.
    Returns:
       A path value pointing to the template file.
    """
    return runtime.label_to_path(_SDK_TEMPLATES[name])

def _get_visibility_list(values):
    """ Returns a string representation of the visibility list.

    If the list is None or empty then ["//visibility:public"] value will be returned.

    Args:
        values: A list of values of None
    Returns:
        A list of visibility parameters
    """
    if not values:
        return ["//visibility:public"]

    visibility_list = []
    for entry in values:
        repo_name = entry.repo_name

        # If this repo_name is empty we change it to refer to the root
        # repo to avoid confusing it with the generated repo.
        if repo_name == "":
            repo_name = "@"
        visibility_list.append("@{}//{}:{}".format(
            repo_name,
            entry.package,
            entry.name,
        ))
    return visibility_list

def _get_target_name(name):
    return name.rpartition("/")[2]

def _get_starlark_label_list(
        values,
        package_prefix = "",
        target_prefix = "",
        target_suffix = ""):
    if not values:
        return ""

    values_str = ""
    for v in values:
        values_str += (
            '    "' +
            package_prefix +
            v +
            ":" +
            target_prefix +
            v.rpartition("/")[2] +
            target_suffix +
            '",\n'
        )
    return values_str

def _get_starlark_list(runtime, values, prefix = "", suffix = "", remove_prefix = ""):
    if not values:
        return ""

    values_str = ""
    for v in values:
        if runtime.value_is_dict(v):
            values_str += "    " + _get_starlark_dict(runtime, v) + ",\n"
        elif runtime.value_is_struct(v):
            values_str += "    " + str(v) + ",\n"
        else:
            if len(remove_prefix) > 0 and v.startswith(remove_prefix):
                v = v[len(remove_prefix):]

            # does not add prefix if value is absolute (starts with "/")
            p = prefix
            if v.startswith("/"):
                p = ""
            values_str += '    "' + p + v + suffix + '",\n'
    return values_str

def _get_starlark_dict(runtime, entries):
    if not entries:
        return ""

    entries_str = ""
    for k in entries.keys():
        v = entries[k]
        if runtime.value_is_list(v):
            v_str = "[" + _get_starlark_list(runtime, v).replace("\n", "") + "]"
        elif runtime.value_is_struct(v):
            v_str += "    " + str(v) + ",\n"
        else:
            v_str = '"' + str(v) + '"'
        entries_str += '    "' + k + '": ' + v_str + ",\n"
    return "{" + entries_str + "}"

def _serialize(runtime, obj):
    """Transitively serializes a starlark object.

    Args:
        runtime: A runtime object.
        obj: Either a list or dict.
    Returns:
        A serialized string representation of the starlark object.
    """
    if runtime.value_is_list(obj):
        return _get_starlark_list(runtime, obj)
    elif runtime.value_is_dict(obj):
        return _get_starlark_dict(runtime, obj)
    else:
        runtime.fail("Unknown type: %s", repr(obj))
        return None  # Make buildifier happy.

def _get_parent_workspace(ctx):
    if ctx.attr.parent_sdk:
        return "@" + ctx.attr.parent_sdk.workspace_name
    else:
        return ""

def _find_dep_path(dep, root_for_relative, parent_sdk, parent_sdk_contents):
    """Determines the dep path to use for the input dep.

    For dep exists in both parent and internal SDKs, the one from parent SDK
    takes precedence.
    """

    # Does not add root if value is absolute (starts with "/")
    p = root_for_relative
    if dep.startswith("/"):
        p = ""
    new_dep = p + dep
    if parent_sdk and parent_sdk_contents and new_dep in parent_sdk_contents:
        with_parent = "@{parent_sdk}//{dep}".format(
            parent_sdk = parent_sdk.workspace_name,
            dep = new_dep,
        )
        new_dep = with_parent
    elif not dep.startswith("/"):
        new_dep = "//" + new_dep
    return new_dep

def _find_dep_paths(deps, root_for_relative, parent_sdk, parent_sdk_contents):
    return [
        _find_dep_path(dep, root_for_relative, parent_sdk, parent_sdk_contents)
        for dep in deps
    ]

def _meta_root_relative_path(meta, filepath):
    """Convert a filepath as it appears in a metadata file into a relative one.

    Args:
      meta: The metadata JSON object.
      filepath: The input file path as it appears in 'meta'.
    Return:
      the file path, relative to the meta["root"] value.
    """

    # NOTE: Keep this in sync with _meta_root_relative_paths() below.
    meta_root = meta["root"].rstrip("/")
    return filepath[len(meta_root) + 1:]

def _meta_root_relative_paths(meta, filepaths):
    """Apply _meta_root_relative_path() to a list of input file paths."""

    # Equivalent to return [_meta_root_relative_path(meta, f) for f in filepaths]
    # without the repeated rstrip("/") calls.
    meta_root = meta["root"].rstrip("/")
    return [f[len(meta_root) + 1:] for f in filepaths]

def _split_internal_external_files(files):
    """Split a list of file paths into internal and external ones.

    An external file path is really a Bazel target label that
    begins with '@' as it points to a different repository.

    An internal file path is a regular file path.
    """
    internal_files = []
    external_files = []
    for f in files:
        if _is_external_file(f):
            external_files.append(f)
        else:
            internal_files.append(f)
    return internal_files, external_files

# buildifier: disable=unused-variable
def _generate_bind_library_build_rules(
        runtime,
        meta,
        relative_dir,
        build_file,
        process_context,
        parent_sdk_contents):
    lib_base_path = meta["root"] + "/"
    _merge_template(
        runtime.ctx,
        build_file,
        _sdk_template_path(runtime, "bind_library"),
        {
            "{{deps}}": _get_starlark_list(runtime, meta["deps"], "//bind/"),
            "{{cc_deps}}": _get_starlark_list(
                runtime,
                meta["deps"],
                "//bind/",
                "",
                "_cc",
            ),
            "{{name}}": _get_target_name(meta["name"]),
            "{{sources}}": _get_starlark_list(
                runtime,
                meta["sources"],
                remove_prefix = lib_base_path,
            ),
        },
    )
    process_context.files_to_copy[meta["_meta_sdk_root"]].extend(
        meta["sources"],
    )

# buildifier: disable=unused-variable
def _generate_sysroot_build_rules(
        runtime,
        meta,
        relative_dir,
        build_file,
        process_context,
        parent_sdk_contents):
    ctx = runtime.ctx
    files = []
    for ifs_file in meta.get("ifs_files", []):
        files.append("pkg/sysroot/" + ifs_file)
    arch_list = process_context.constants.target_cpus

    # TODO(https://fxbug.dev/385408047): Prefer API level-specific "variants"
    # instances when available. Then use values from "versions" for "HEAD" only
    # when "variants" does not include "HEAD".
    if not "versions" in meta:
        fail("The Bazel SDK does not yet support versioned sysroots and thus requires 'versions'.")

    # TODO(https://fxbug.dev/385406226): Remove this block once the SDK always
    # includes artifacts for "HEAD" in "variants".
    for arch in arch_list:
        meta_for_arch = meta["versions"][arch]
        if "debug_libs" in meta_for_arch:
            files.extend(meta_for_arch["debug_libs"])
        if "dist_libs" in meta_for_arch:
            files.extend(meta_for_arch["dist_libs"])
        if "headers" in meta_for_arch:
            files.extend(meta_for_arch["headers"])
        if "link_libs" in meta_for_arch:
            files.extend(meta_for_arch["link_libs"])

    process_context.files_to_copy[meta["_meta_sdk_root"]].extend(files)

    _merge_template(
        ctx,
        build_file,
        _sdk_template_path(runtime, "sysroot"),
        {
            "{{relative_dir}}": relative_dir,
        },
    )

    for arch in arch_list:
        srcs = {}

        # Expected dist_dir = "arch/x64/sysroot"
        dist_dir = meta["versions"][arch]["dist_dir"]

        libs_base = dist_dir + "/dist/lib/"
        for dist_lib in meta["versions"][arch]["dist_libs"]:
            if _is_external_file(dist_lib):
                # Expect dist_lib as @fuchsia_idk//arch/x64/sysroot:dist/lib/FOO
                # Compute:
                #    repo_name        = fuchsia_idk
                #    dist_path        = arch/x64/sysroot/dist/lib/FOO
                #    dist_lib_subpath = FOO
                #    strip_prefix     = arch/x64/sysroot/dist/lib/
                repo_name, _, label = dist_lib.partition("//")
                repo_name = repo_name[1:]  # Remove initial @
                dist_path = label.replace(":", "/")
            else:
                # Expect dist_lib as arch/x64/sysroot/dist/lib/FOO
                # Compute:
                #    repo_name        = fuchsia_sdk   (current repository name)
                #    dist_path        = arch/x64/sysroot/dist/lib/FOO
                #    dist_lib_subpath = FOO
                #    strip_prefix     = arch/x64/sysroot/dist/lib/
                repo_name = ctx.attr.name
                dist_path = dist_lib

            dist_lib_subpath = dist_path.removeprefix(libs_base)
            strip_prefix = "%s/dist/lib/" % (dist_dir)

            # dist_lib_subpath can be 'libfoo.so' or '<variant>/libfoo.so'
            variant, _, _ = dist_lib_subpath.rpartition("/")
            variant_config = _FUCHSIA_CLANG_VARIANT_MAP[variant]
            srcs.setdefault(variant_config, []).append(_final_bazel_path(dist_lib))

        per_arch_build_file = build_file.dirname.get_child(arch).get_child(
            "BUILD.bazel",
        )
        ctx.file(per_arch_build_file, content = _header(), executable = False)
        _merge_template(
            ctx,
            per_arch_build_file,
            _sdk_template_path(runtime, "sysroot_arch_sub"),
            {
                "{{srcs}}": _get_starlark_dict(runtime, srcs),
                "{{strip_prefix}}": strip_prefix,
            },
        )

def _ffx_tool_files(meta, files_str):
    for name, collection in meta.items():
        if name == "executable" or name == "executable_metadata":
            # each set of file collections can only have one each of an
            # executable and executable_metadata item, so we expect to just
            # add one item.
            files_str.append(collection)
        else:
            # any other kind of collection must be an array if present, so
            # we extend the list.
            files_str.extend(collection)

# buildifier: disable=unused-variable
def _generate_ffx_subtool_build_rules(
        runtime,
        meta,
        relative_dir,
        build_file,
        process_context,
        parent_sdk_contents):
    # Include meta manifest itself because ffx uses it to locate ffx tools.
    files_str = [meta["_meta_path"]]
    if "files" in meta:
        _ffx_tool_files(meta["files"], files_str)

    if "target_files" in meta:
        for arch in meta["target_files"]:
            _ffx_tool_files(meta["target_files"][arch], files_str)

    internal_files, external_files = _split_internal_external_files(files_str)

    if internal_files:
        relative_files = _meta_root_relative_paths(meta, internal_files)

        _merge_template(
            runtime.ctx,
            build_file,
            _sdk_template_path(runtime, "ffx_subtool"),
            {
                "{{files}}": _get_starlark_list(runtime, relative_files),
            },
        )
        process_context.files_to_copy[meta["_meta_sdk_root"]].extend(internal_files)

    for file in external_files:
        repository, _, label = file.partition("//")
        relative_file = _meta_root_relative_path(meta, label.replace(":", "/"))

        _merge_template(
            runtime.ctx,
            build_file,
            _sdk_template_path(runtime, "ffx_subtool_external"),
            {
                "{{name}}": relative_file,
                "{{actual}}": file,
            },
        )

# buildifier: disable=unused-variable
def _generate_host_tool_build_rules(
        runtime,
        meta,
        relative_dir,
        build_file,
        process_context,
        parent_sdk_contents):
    ctx = runtime.ctx

    # Include meta manifest itself because ffx uses it to locate host tools.
    files_str = [meta["_meta_path"]]
    if "files" in meta:
        files_str.extend(meta["files"])
    elif "target_files" in meta:
        for arch in meta["target_files"]:
            files_str.extend(meta["target_files"][arch])

    internal_files, external_files = _split_internal_external_files(files_str)
    if internal_files:
        relative_files = _meta_root_relative_paths(meta, internal_files)

        _merge_template(
            ctx,
            build_file,
            _sdk_template_path(runtime, "host_tool"),
            {
                "{{files}}": _get_starlark_list(runtime, relative_files),
            },
        )
        process_context.files_to_copy[meta["_meta_sdk_root"]].extend(internal_files)

    for file in external_files:
        repository, _, label = file.partition("//")
        relative_file = _meta_root_relative_path(meta, label.replace(":", "/"))

        _merge_template(
            ctx,
            build_file,
            _sdk_template_path(runtime, "host_tool_external"),
            {
                "{{name}}": relative_file,
                "{{actual}}": file,
            },
        )

# buildifier: disable=unused-variable
def _generate_companion_host_tool_build_rules(
        runtime,
        meta,
        relative_dir,
        build_file,
        process_context,
        parent_sdk_contents):
    ctx = runtime.ctx

    # the metadata file itself is needed by the emulator
    files_str = [str(meta["_meta_path"])]

    if "files" in meta:
        files_str.extend(meta["files"])
    elif "target_files" in meta:
        for arch in meta["target_files"]:
            files_str.extend(meta["target_files"][arch])

    internal_files, external_files = _split_internal_external_files(files_str)

    tool_files = _meta_root_relative_paths(meta, internal_files) + external_files

    # SDK metadata has one companion_host_tool metadata for each architecture, but they are rooted in the same location (//tools)
    # and have the same name (eg aemu_internal). If we just reuse the metadata name, there will be a conflict in Bazel, as there
    # will be two Bazel rules with the same name in the same BUILD.bazel file, one for each host architecture.
    # To avoid this conflict, we find the architecture in the metadata file path and append it to the metadata name, eg aemu_internal_x64
    if meta["_meta_path"].find("x64") >= 0:
        name = meta["name"] + "_x64"
    elif meta["_meta_path"].find("arm64") >= 0:
        name = meta["name"] + "_arm64"
    else:
        name = meta["name"]

    _merge_template(
        ctx,
        build_file,
        _sdk_template_path(runtime, "companion_host_tool"),
        {
            "{{name}}": name,
            "{{files}}": _get_starlark_list(runtime, tool_files),
        },
    )

    process_context.files_to_copy[meta["_meta_sdk_root"]].extend(files_str)

# Only numerical API levels in the Supported phase and the mutable API level
# "NEXT" are supported in the IDK and SDKs.
# "HEAD" is technically not supported in the IDK or SDK(s) - see
# https://fxbug.dev/334936990 - but it is currently used (without proper
# versioning) in-tree.
# buildifier: disable=unused-variable
def _generate_api_version_rules(
        runtime,
        meta,
        relative_dir,
        build_file,
        process_context,
        parent_sdk_contents):
    ctx = runtime.ctx
    supported_api_levels = []
    unsupported_api_levels = []
    for api_level, value in meta["data"]["api_levels"].items():
        level = runtime.make_struct(
            abi_revision = value["abi_revision"],
            api_level = api_level,
            as_u32 = int(api_level),
        )
        if value["status"] == "supported":
            supported_api_levels.append(level)
        else:
            unsupported_api_levels.append(level)

    for api_level, value in meta["data"]["special_api_levels"].items():
        if api_level == "NEXT" or api_level == "HEAD":
            supported_api_levels.append(
                runtime.make_struct(
                    abi_revision = value["abi_revision"],
                    api_level = api_level,
                    as_u32 = value["as_u32"],
                ),
            )
        elif api_level == "PLATFORM":
            # "PLATFORM" is for Platform use only and not "known" to the SDK.
            pass

        else:
            fail("Unrecognized special API level '%s'" % api_level)

    # unlike other template rules that affect the corresponding BUILD.bazel file,
    # the api_version template creates a api_version.bzl file that is loaded in
    # the top-level BUILD.bazel created by fuchsia_sdk_repository_template.BUILD.
    bzl_file = ctx.path(build_file).dirname.get_child("api_version.bzl")

    _merge_template(
        ctx,
        bzl_file,
        _sdk_template_path(runtime, "api_version"),
        {
            "{{supported_api_levels}}": _get_starlark_list(runtime, supported_api_levels),
            "{{unsupported_api_levels}}": _get_starlark_list(runtime, unsupported_api_levels),
        },
    )

    constraint_build_file = _constraints_build_file(ctx)

    # writes the api level constraints to the constraints build file
    _merge_template(
        ctx,
        constraint_build_file,
        _sdk_template_path(runtime, "api_level_constraint"),
        {
            "{{target_cpus}}": _get_starlark_list(runtime, process_context.constants.target_cpus),
        },
    )

    # write the api level flags
    flags_build_file = _flags_build_file(ctx)

    # writes the api level constraints to the constraints build file
    _merge_template(
        ctx,
        flags_build_file,
        _sdk_template_path(runtime, "api_level_flag"),
        {},
    )

# buildifier: disable=unused-variable
def _generate_fidl_library_build_rules(
        runtime,
        meta,
        relative_dir,
        build_file,
        process_context,
        parent_sdk_contents):
    ctx = runtime.ctx
    lib_base_path = meta["root"] + "/"

    deps = _find_dep_paths(
        meta["deps"],
        "fidl/",
        ctx.attr.parent_sdk,
        parent_sdk_contents,
    )

    hlcpp_visibility = _get_visibility_list(
        process_context.visibility_templates.get(HLCPP_VISIBILITY_KEY, None),
    )

    _merge_template(
        ctx,
        build_file,
        _sdk_template_path(runtime, "fidl_library"),
        {
            "{{deps}}": _get_starlark_list(runtime, deps),
            "{{name}}": _get_target_name(meta["name"]),
            "{{sources}}": _get_starlark_list(
                runtime,
                meta["sources"],
                remove_prefix = lib_base_path,
            ),
            "{{parent_sdk}}": _get_parent_workspace(ctx),
            # the substitutions below are only used by legacy fidl libraries. Remove them when
            # the legacy fidl cc libraries are removed.
            "{{cc_deps}}": _get_starlark_label_list(deps, "", "", "_cc"),
            "{{llcpp_deps}}": _get_starlark_label_list(
                deps,
                "",
                "",
                "_llcpp_cc",
            ),
            "{{hlcpp_visibility}}": _get_starlark_list(runtime, hlcpp_visibility),
        },
    )
    process_context.files_to_copy[meta["_meta_sdk_root"]].extend(
        meta["sources"],
    )

# buildifier: disable=unused-variable
def _generate_component_manifest_rules(
        runtime,
        meta,
        relative_dir,
        build_file,
        process_context,
        parent_sdk_contents):
    if "data" in meta:
        lib_name = meta["name"]
        for f in meta["data"]:
            if f.endswith(".cml"):
                # The include_path for a package like "/pkg/inspect/client.shard.cml is "/pkg", but
                # this information is not explicitly encoded in the metadata.
                # The code below finds the includepath by breaking the shard filename into three pieces:
                #     <include_path></lib_name/><shard_filename>
                parts = f.partition("/%s/" % lib_name)
                include_path = parts[0]
                shard_name = parts[2]
                name = shard_name.removesuffix(".cml").removesuffix(".shard")

                # Keep track of all the labels that we create to add to the toolchain
                target_label = "//{}/{}:{}".format(include_path, lib_name, name)
                process_context.component_manifest_targets.append(target_label)

                _merge_template(
                    runtime.ctx,
                    build_file,
                    _sdk_template_path(runtime, "component_manifest"),
                    {
                        "{{name}}": name,
                        "{{source}}": shard_name,
                        "{{include_path}}": include_path,
                    },
                )
                process_context.files_to_copy[meta["_meta_sdk_root"]].append(f)

# A list of copt overrides to provide to an individual library. Care should be used
# when adding anythying to this list as it adds copts for a library in a way that is
# hard to find for users.
_CC_LIBRARY_COPTS_OVERRIDES = {
    "zxtest": [
        # TODO(https://fxbug.dev/42085293): zxtest headers use VLA, rather than suppressing
        # every use of zxtest headers of which there are many, we suppress it here.
        "-Wno-vla-cxx-extension",
    ],
}

# alwayslink attr provide to an individual library. This should mostly be
# used in tests when we don't care about unused symbol getting linked.
# This is a workaround for driver testing before Bazel 7 is used in-tree.
_ALWAYSLINK_LIBS = [
    "driver_testing_cpp",
]

# buildifier: disable=unused-variable
def _generate_cc_source_library_build_rules(
        runtime,
        meta,
        relative_dir,
        build_file,
        process_context,
        parent_sdk_contents):
    ctx = runtime.ctx
    lib_base_path = meta["root"] + "/"
    fidl_deps = []
    fidl_llcpp_deps = []
    if "fidl_binding_deps" in meta:
        # Example:    { "binding_type": "hlcpp", "deps": [ "fuchsia.images" ] }
        for deps_per_type in meta["fidl_binding_deps"]:
            binding_type = deps_per_type["binding_type"]
            if binding_type == "hlcpp":
                suffixes = ["cc"]
            else:
                suffixes = ["cpp", "cpp_driver", "cpp_driver_wire", "cpp_wire"]
            for fidl in deps_per_type["deps"]:
                dep_path = _find_dep_path(
                    fidl,
                    "fidl/",
                    ctx.attr.parent_sdk,
                    parent_sdk_contents,
                )
                fidl_deps.extend(
                    [
                        dep_path + ":" + fidl + "_" + suffix
                        for suffix in suffixes
                    ],
                )
    elif "fidl_deps" in meta:
        for fidl in meta["fidl_deps"]:
            dep_path = _find_dep_path(
                fidl,
                "fidl/",
                ctx.attr.parent_sdk,
                parent_sdk_contents,
            )
            fidl_deps.append(dep_path + ":" + fidl + "_cc")
            fidl_llcpp_deps.append(dep_path + ":" + fidl + "_llcpp_cc")

    deps = []
    for bind in meta.get("bind_deps", []):
        dep_path = _find_dep_path(
            bind,
            "bind/",
            ctx.attr.parent_sdk,
            parent_sdk_contents,
        )
        deps.append(dep_path + ":" + bind + "_cc")

    deps += _find_dep_paths(
        meta["deps"],
        "pkg/",
        ctx.attr.parent_sdk,
        parent_sdk_contents,
    )
    target_name = _get_target_name(meta["name"])
    copts = _CC_LIBRARY_COPTS_OVERRIDES.get(target_name, [])
    alwayslink = target_name in _ALWAYSLINK_LIBS

    # Note: srcs = meta["sources"] does not copy the contents so we need to make
    # sure we do a copy here otherwise the target will get added to the
    # files_to_copy list resulting in a broken symlink.
    srcs = [s for s in meta["sources"]]
    verify_cc_head_api_level_name = (
        _get_target_name(meta["name"]) + "_verify_cc_head_api_level"
    )
    if meta["stable"] == False:
        srcs.append(":" + verify_cc_head_api_level_name)
    _merge_template(
        ctx,
        build_file,
        _sdk_template_path(runtime, "cc_library"),
        {
            "{{deps}}": _get_starlark_list(runtime, deps),
            "{{fidl_deps}}": _get_starlark_list(runtime, fidl_deps),
            "{{fidl_llcpp_deps}}": _get_starlark_list(runtime, fidl_llcpp_deps),
            "{{name}}": _get_target_name(meta["name"]),
            "{{sources}}": _get_starlark_list(
                runtime,
                srcs,
                remove_prefix = lib_base_path,
            ),
            "{{headers}}": _get_starlark_list(
                runtime,
                meta["headers"],
                remove_prefix = lib_base_path,
            ),
            "{{relative_include_dir}}": meta["include_dir"][len(lib_base_path):],
            "{{copts}}": _get_starlark_list(runtime, copts),
            "{{alwayslink}}": str(alwayslink),
            "{{verify_cc_head_api_level_name}}": verify_cc_head_api_level_name,
        },
    )
    process_context.files_to_copy[meta["_meta_sdk_root"]].extend(
        meta["sources"],
    )
    process_context.files_to_copy[meta["_meta_sdk_root"]].extend(
        meta["headers"],
    )

# Maps a Bazel cpu name to its Fuchsia name.
_TO_FUCHSIA_CPU_NAME_MAP = {
    "x86_64": "x64",
    "k8": "x64",
    "aarch64": "arm64",
}

def _to_fuchsia_cpu_name(cpu_name):
    return _TO_FUCHSIA_CPU_NAME_MAP.get(cpu_name, cpu_name)

# Maps a Fuchsia cpu name to the corresponding config_setting() label in
# @rules_fuchsia//fuchsia/constraints
_FUCHSIA_CPU_CONSTRAINT_MAP = {
    "x64": "@rules_fuchsia//fuchsia/constraints:cpu_x64",
    "arm64": "@rules_fuchsia//fuchsia/constraints:cpu_arm64",
    "riscv64": "@rules_fuchsia//fuchsia/constraints:cpu_riscv64",
}

# Maps a variant name to the corresponding config_setting() label in
# @fuchsia_clang
_FUCHSIA_CLANG_VARIANT_MAP = {
    "": "@fuchsia_clang//:novariant",
    "asan": "@fuchsia_clang//:asan_variant",
    "hwasan": "@fuchsia_clang//:hwasan_variant",
}

def _get_api_level(variant):
    return variant["api_level"]

# We can't just do f"//:{file}" for file srcs, since the relative dir may have a
# BUILD.bazel file, making that subdir its own Bazel package.
def _bazel_file_path(relative_dir, file):
    if _is_external_file(file):
        return file

    prefix = relative_dir if file.startswith(relative_dir) else ""
    suffix = file[len(prefix):].lstrip("/")
    return "//%s:%s" % (prefix, suffix)

# buildifier: disable=unused-variable
def _generate_cc_prebuilt_library_build_rules(
        runtime,
        meta,
        relative_dir,
        build_file,
        process_context,
        parent_sdk_contents):
    ctx = runtime.ctx
    lib_base_path = meta["root"] + "/"

    meta_sdk_root = meta["_meta_sdk_root"]

    deps = _find_dep_paths(
        meta["deps"],
        "pkg/",
        ctx.attr.parent_sdk,
        parent_sdk_contents,
    )
    subs = {
        "{{deps}}": _get_starlark_list(runtime, deps),
        "{{name}}": _get_target_name(meta["name"]),
        "{{headers}}": _get_starlark_list(
            runtime,
            meta["headers"],
            remove_prefix = lib_base_path,
        ),
        "{{relative_include_dir}}": meta["include_dir"][len(lib_base_path):],
    }
    files = meta["headers"]
    if "ifs" in meta:
        files.append(lib_base_path + meta["ifs"])
    process_context.files_to_copy[meta_sdk_root].extend(files)

    prebuilt_select = {}
    dist_select = {}

    has_distlibs = False

    # Process the arch directories first then the variants, so that the variants
    # will override the arch directories when both are present.
    # TODO(https://fxbug.dev/385406226): Remove the first two for loops once
    # //sdk:bazel_internal_only_libs no longer contains any prebuilts.

    # Process "binaries" if present.
    if "binaries" in meta:
        # add all supported architectures to the select, even if they are not available in the current SDK,
        # so that SDKs for different architectures can be composed by a simple directory merge.
        arch_list = process_context.constants.target_cpus
        for arch in arch_list:
            constraint = "@fuchsia_sdk//constraints:is_%s_api_HEAD" % (arch)
            dist_select[constraint] = ["//%s/%s-HEAD:dist" % (relative_dir, arch)]
            prebuilt_select[constraint] = [
                "//%s/%s-HEAD:prebuilts" % (relative_dir, arch),
            ]

        for arch in arch_list:
            head_dirname = "%s-HEAD" % (arch)
            per_arch_build_file = build_file.dirname.get_child(
                head_dirname,
            ).get_child("BUILD.bazel")
            ctx.file(per_arch_build_file, content = _header(), executable = False)

            linklib = meta["binaries"][arch]["link"]
            _merge_template(
                ctx,
                per_arch_build_file,
                _sdk_template_path(runtime, "cc_prebuilt_library_linklib"),
                {
                    "{{link_lib}}": _final_bazel_path(linklib),
                    "{{library_type}}": meta["format"],
                },
            )
            process_context.files_to_copy[meta_sdk_root].append(linklib)

            if "dist" in meta["binaries"][arch]:
                has_distlibs = True
                dist_lib = meta["binaries"][arch]["dist"]
                process_context.files_to_copy[meta_sdk_root].append(
                    dist_lib,
                )

                debug_lib = meta["binaries"][arch].get("debug", dist_lib)
                _merge_template(
                    ctx,
                    per_arch_build_file,
                    _sdk_template_path(
                        runtime,
                        "cc_prebuilt_library_distlib",
                    ),
                    {
                        "{{stripped_file}}": _final_bazel_path(dist_lib),
                        "{{unstripped_file}}": _final_bazel_path(debug_lib),
                        "{{dist_path}}": meta["binaries"][arch]["dist_path"],
                    },
                )
                if debug_lib != dist_lib:
                    process_context.files_to_copy[meta_sdk_root].append(debug_lib)

    # Process "variants".

    prebuilt_variants = []
    if "variants" in meta:
        for variant in meta["variants"]:
            arch = variant["constraints"]["arch"]
            api_level = variant["constraints"]["api_level"]
            values = variant["values"]

            prebuilt_variants.append(
                runtime.make_struct(
                    name = "%s-api-%s" % (arch, api_level),
                    link_lib = values["link_lib"],
                    constraint = "@fuchsia_sdk//constraints:is_%s_api_%s" %
                                 (arch, api_level),
                    os = "@platforms//os:fuchsia",
                    arch = arch,
                    api_level = api_level,
                    has_debug = "debug" in values,
                    debug = values["debug"] if "debug" in values else None,
                    has_dist_lib = "dist_lib" in values,
                    dist_lib = values["dist_lib"] if "dist_lib" in values else None,
                    dist_lib_dest = values["dist_lib_dest"] if "dist_lib_dest" in values else None,
                ),
            )

    for variant in prebuilt_variants:
        constraint = "@fuchsia_sdk//constraints:is_%s_api_%s" % (
            variant.arch,
            variant.api_level,
        )
        dist_select[constraint] = [
            "//%s/%s:dist" % (relative_dir, variant.name),
        ]
        prebuilt_select[constraint] = [
            "//%s/%s:prebuilts" % (relative_dir, variant.name),
        ]

        per_arch_x_api_build_file = build_file.dirname.get_child(
            variant.name,
        ).get_child("BUILD.bazel")
        ctx.file(per_arch_x_api_build_file, content = _header(), executable = False)

        _merge_template(
            ctx,
            per_arch_x_api_build_file,
            _sdk_template_path(runtime, "cc_prebuilt_library_linklib"),
            {
                "{{link_lib}}": _final_bazel_path(variant.link_lib),
                "{{library_type}}": meta["format"],
            },
        )
        process_context.files_to_copy[meta_sdk_root].append(
            variant.link_lib,
        )

        if variant.has_dist_lib:
            dist_lib = variant.dist_lib
            process_context.files_to_copy[meta_sdk_root].append(
                dist_lib,
            )

            debug_lib = variant.debug if variant.has_debug else dist_lib
            _merge_template(
                ctx,
                per_arch_x_api_build_file,
                _sdk_template_path(
                    runtime,
                    "cc_prebuilt_library_distlib",
                ),
                {
                    "{{stripped_file}}": _final_bazel_path(dist_lib),
                    "{{unstripped_file}}": _final_bazel_path(debug_lib),
                    "{{dist_path}}": variant.dist_lib_dest,
                },
            )
            if debug_lib != dist_lib:
                process_context.files_to_copy[meta_sdk_root].append(debug_lib)

    # Apply the results.

    prebuilt_select_str = (
        "variant_select(" + _get_starlark_dict(runtime, prebuilt_select) + ")"
    )

    # Assumption: if one architecture doesn't have distlib binaries for this library,
    # the other architectures will also not have them.
    if has_distlibs:
        dist_select_str = (
            "variant_select(" + _get_starlark_dict(runtime, dist_select) + ")"
        )
    else:
        dist_select_str = "[]"

    subs.update(
        {
            "{{prebuilt_select}}": prebuilt_select_str,
            "{{dist_select}}": dist_select_str,
        },
    )
    _merge_template(
        ctx,
        build_file,
        _sdk_template_path(runtime, "cc_prebuilt_library"),
        subs,
    )

# buildifier: disable=unused-variable
def _generate_package_build_rules(
        runtime,
        meta,
        relative_dir,
        build_file,
        process_context,
        parent_sdk_contents):
    ctx = runtime.ctx
    _merge_template(
        ctx,
        build_file,
        _sdk_template_path(runtime, "export_all_files"),
    )

    # Parse package variants from metadata.
    name = _get_target_name(meta["name"])

    package_variants = [
        runtime.make_struct(
            name = "%s_%s_api_%s" %
                   (name, variant["arch"], _get_api_level(variant)),
            files = variant["files"],
            manifest = variant["manifest_file"],
            constraint = "is_%s_api_%s" %
                         (variant["arch"], _get_api_level(variant)),
            os = "@platforms//os:fuchsia",
            cpu = _FUCHSIA_CPU_CONSTRAINT_MAP[variant["arch"]],
            api_level = "//constraints:api_level_%s" % _get_api_level(variant),
        )
        for variant in meta["variants"]
    ]

    for variant in package_variants:
        # Write build defs for each package variant.
        _merge_template(
            ctx,
            build_file,
            _sdk_template_path(runtime, "package"),
            {
                "{{name}}": variant.name,
                "{{files}}": _get_starlark_list(
                    runtime,
                    [
                        _bazel_file_path(relative_dir, file)
                        for file in variant.files
                    ],
                ),
                "{{manifest}}": _bazel_file_path(
                    relative_dir,
                    variant.manifest,
                ),
            },
        )
        process_context.files_to_copy[meta["_meta_sdk_root"]].extend(
            variant.files,
        )

    _merge_template(
        ctx,
        build_file,
        _sdk_template_path(runtime, "select_alias"),
        {
            "{{name}}": name,
            "{{select_map}}": _get_starlark_dict(
                runtime,
                {
                    "//constraints:%s" %
                    variant.constraint: ":%s" % variant.name
                    for variant in package_variants
                },
            ),
        },
    )

# buildifier: disable=unused-variable
def _generate_config_build_rules(
        runtime,
        meta,
        relative_dir,
        build_file,
        process_context,
        parent_sdk_contents):
    ctx = runtime.ctx
    process_context.files_to_copy[meta["_meta_sdk_root"]].extend(meta["data"])

    _merge_template(
        ctx,
        build_file,
        _sdk_template_path(runtime, "filegroup"),
        {
            "{{name}}": _get_target_name(meta["name"]),
            "{{srcs}}": _get_starlark_list(
                runtime,
                [_bazel_file_path(relative_dir, src) for src in meta["data"]],
            ),
        },
    )

# buildifier: disable=unused-variable
def _generate_python_e2e_test_rules(
        runtime,
        meta,
        relative_dir,
        build_file,
        process_context,
        parent_sdk_contents):
    # Helper functions to handle the unversioned tests.
    # TODO(https://fxbug.dev/330373943): Remove once tests are versioned.
    def _fuchsia_api_level_constraint(api_level, default = "//conditions:default"):
        if _is_undefined_api_level(api_level):
            return default
        return "//constraints:api_level_%s" % api_level

    def _api_level_deprecation_message(api_level):
        if _is_undefined_api_level(api_level):
            return '"Warning: Dependencies with unstable API levels are being used, incompatibility may occur."'
        return "None"

    def _is_undefined_api_level(api_level):
        return api_level == "unversioned"

    ctx = runtime.ctx
    process_context.files_to_copy[meta["_meta_sdk_root"]].extend(meta["files"])

    # Seggregate data files based on api level from metadata.
    files_for_api_level = {}
    internal_files, external_files = _split_internal_external_files(meta["files"])
    for file in internal_files:
        if not file.startswith(meta["root"]):
            # buildifier: disable=print
            print(
                "WARNING: Ignoring file %s that is outside of %s" %
                (file, meta["root"]),
            )
            continue
        file = _meta_root_relative_path(meta, file)
        api_level, _, file = file.partition("/")
        if api_level not in files_for_api_level:
            files_for_api_level[api_level] = []
        files_for_api_level[api_level].append(file)

    # Write api level specific targets.
    name = _get_target_name(meta["name"])
    for api_level, files in files_for_api_level.items():
        subpackage_build_file = "%s/%s/BUILD.bazel" % (relative_dir, api_level)
        ctx.file(subpackage_build_file, content = _header())
        _merge_template(
            ctx,
            subpackage_build_file,
            _sdk_template_path(runtime, "prebuilt_lacewing_test"),
            {
                "{{name}}": name,
                "{{test_binary}}": "%s_bin" % name,
                "{{data}}": _get_starlark_list(runtime, files),
                "{{deprecation}}": _api_level_deprecation_message(api_level),
            },
        )

    _merge_template(
        ctx,
        build_file,
        _sdk_template_path(runtime, "select_alias"),
        {
            "{{name}}": name,
            "{{select_map}}": _get_starlark_dict(
                runtime,
                {
                    _fuchsia_api_level_constraint(api_level): "//%s/%s:%s" %
                                                              (relative_dir, api_level, name)
                    for api_level in files_for_api_level
                } | {
                    "//conditions:default": "//:empty",
                },
            ),
        },
    )

# buildifier: disable=unused-variable
def _generate_loadable_module_build_rules(
        runtime,
        meta,
        relative_dir,
        build_file,
        process_context,
        parent_sdk_contents):
    ctx = runtime.ctx
    arch_list = process_context.constants.target_cpus
    files = []
    files.extend(meta["resources"])
    name = _get_target_name(meta["name"])
    dest_prefix = "lib/"

    # Special handling for devicetree visitors
    if name.startswith("devicetree"):
        dest_prefix += "visitors/"
    for arch in arch_list:
        files.extend(meta["binaries"][arch])

        # Create sub BUILD file
        per_arch_build_file = build_file.dirname.get_child(arch).get_child(
            "BUILD.bazel",
        )
        ctx.file(per_arch_build_file, content = _header(), executable = False)
        _merge_template(
            ctx,
            per_arch_build_file,
            _sdk_template_path(runtime, "loadable_module_sub"),
            {
                "{{name}}": name,
                "{{srcs}}": _get_starlark_list(
                    runtime,
                    [
                        _bazel_file_path(relative_dir, src)
                        for src in meta["binaries"][arch]
                    ],
                ),
                "{{dest}}": dest_prefix,
            },
        )

    process_context.files_to_copy[meta["_meta_sdk_root"]].extend(files)

    _merge_template(
        ctx,
        build_file,
        _sdk_template_path(runtime, "loadable_module"),
        {
            "{{name}}": name,
            "{{relative_dir}}": relative_dir,
            "{{resources}}": _get_starlark_list(
                runtime,
                [
                    _bazel_file_path(relative_dir, data)
                    for data in meta["resources"]
                ],
            ),
            "{{dest}}": dest_prefix,
        },
    )

def _merge_template(ctx, target_build_file, template_file, subs = {}):
    if ctx.path(target_build_file).exists:
        existing_content = ctx.read(target_build_file)
    else:
        existing_content = ""

    ctx.template(target_build_file, template_file, subs, executable = False)

    if existing_content != "":
        new_content = ctx.read(target_build_file)
        ctx.file(
            target_build_file,
            content = existing_content + "\n" + new_content,
            executable = False,
        )

def _process_dir(
        runtime,
        relative_dir,
        libraries,
        process_context,
        parent_sdk_contents):
    generators = {
        "bind_library": _generate_bind_library_build_rules,
        "cc_prebuilt_library": _generate_cc_prebuilt_library_build_rules,
        "cc_source_library": _generate_cc_source_library_build_rules,
        "companion_host_tool": _generate_companion_host_tool_build_rules,
        "component_manifest": _generate_component_manifest_rules,
        "config": _generate_config_build_rules,
        "experimental_python_e2e_test": _generate_python_e2e_test_rules,
        "ffx_tool": _generate_ffx_subtool_build_rules,
        "fidl_library": _generate_fidl_library_build_rules,
        "host_tool": _generate_host_tool_build_rules,
        "loadable_module": _generate_loadable_module_build_rules,
        "package": _generate_package_build_rules,
        "sysroot": _generate_sysroot_build_rules,
        "version_history": _generate_api_version_rules,
    }

    ctx = runtime.ctx
    build_file = ctx.path(relative_dir).get_child("BUILD.bazel")

    for meta in libraries:
        t = _type_from_meta(runtime, meta)

        generator = generators.get(t)
        if generator == None:
            continue

        if not build_file.exists:
            ctx.file(build_file, content = _header(), executable = False)

        generator(
            runtime,
            meta,
            relative_dir,
            build_file,
            process_context,
            parent_sdk_contents,
        )

def _write_cmc_includes(runtime, process_context):
    # write the cmc includes to the BUILD file
    ctx = runtime.ctx
    build_file = _root_build_file(ctx)
    _merge_template(
        ctx,
        build_file,
        _sdk_template_path(runtime, "component_manifest_collection"),
        {
            "{{name}}": "cmc_includes",
            "{{deps}}": str(process_context.component_manifest_targets),
        },
    )

def _root_build_file(ctx):
    return ctx.path("BUILD.bazel")

def _constraints_build_file(ctx):
    build_file = _root_build_file(ctx).dirname.get_child("constraints").get_child("BUILD.bazel")
    if not build_file.exists:
        ctx.file(build_file, content = _header(), executable = False)
    return build_file

def _flags_build_file(ctx):
    build_file = _root_build_file(ctx).dirname.get_child("flags").get_child("BUILD.bazel")
    if not build_file.exists:
        ctx.file(build_file, content = _header(), executable = False)
    return build_file

def _type_from_meta(runtime, meta):
    if "type" in meta:
        return meta["type"]
    elif "data" in meta and "type" in meta["data"]:
        return meta["data"]["type"]
    else:
        runtime.fail(
            "Internal SDK generation error: cannot identify type of library: %s" %
            meta,
        )
        return None  # Make buildifier happy.

def _path_in_root(repo_ctx, root, rel_path):
    return repo_ctx.path("%s/%s" % (root, rel_path))

def _sdk_id_from_manifests(runtime, manifests):
    # buildifier: disable=function-docstring-args
    # buildifier: disable=function-docstring-return
    """Gets the SDK id from the given manifests.

    This assumes all of the manifests have the same id and thus only uses the first manifest
    in the list. If no id is found an empty string will be returned.
    """
    id = ""
    if len(manifests) > 0:
        ctx = runtime.ctx
        manifest = manifests[0]
        root = manifest.get("root")
        manifest_path = manifest.get("manifest")
        json_obj = runtime.json_decode(
            ctx.read(_path_in_root(ctx, root, manifest_path)),
        )
        id = json_obj.get("id")

    return id

# buildifier: disable=function-docstring
def _load_parent_sdk_metadata(runtime, parent_sdk_contents):
    ctx = runtime.ctx
    if not ctx.attr.parent_sdk or not ctx.attr.parent_sdk_local_paths:
        return

    for path in ctx.attr.parent_sdk_local_paths:
        local_sdk = runtime.workspace_path(path)
        if not local_sdk.exists:
            runtime.fail("Cannot find parent SDK: %s" % local_sdk)

        root = "%s/." % local_sdk
        manifest_path = "meta/manifest.json"
        json_obj = runtime.json_decode(
            ctx.read(_path_in_root(ctx, root, manifest_path)),
        )

        for part in json_obj["parts"]:
            meta_file_rel = part["meta"]
            meta_file_with_root = _path_in_root(ctx, root, meta_file_rel)
            meta = runtime.json_decode(ctx.read(meta_file_with_root))

            if "root" in meta:
                dir = meta["root"]
            else:
                dir = meta_file_rel.rpartition("/")[0]

            if "name" in meta:
                key = "%s" % dir
                parent_sdk_contents[key] = meta

def _generate_sdk_constants(runtime, manifests):
    """Generates generated_constants.bzl from the sdk metadata

    Args:
        runtime: A runtime value.
        manifests: a list of paths to the meta data manifests.

    Returns:
        A struct mapping the content of generated_constants.bzl
    """
    repo_ctx = runtime.ctx
    host_cpu_names_set = {}
    target_cpu_names_set = {}
    all_cc_source_targets_map = {}
    for manifest_obj in manifests:
        root = manifest_obj.get("root")
        manifest_path = manifest_obj.get("manifest")
        json_obj = runtime.json_decode(
            repo_ctx.read(_path_in_root(repo_ctx, root, manifest_path)),
        )
        host_os = json_obj["arch"]["host"]
        host_cpu = _to_fuchsia_cpu_name(host_os.split("-")[0])
        host_cpu_names_set[host_cpu] = None
        for cpu_name in json_obj["arch"]["target"]:
            target_cpu_names_set[cpu_name] = None

        all_cc_source_metas = [
            part["meta"]
            for part in json_obj["parts"]
            if part["type"] in ["cc_source_library"]
        ]

        for meta_path in all_cc_source_metas:
            meta_obj = runtime.json_decode(
                repo_ctx.read(_path_in_root(repo_ctx, root, meta_path)),
            )
            target = "//{}:{}".format(meta_obj["root"], meta_obj["name"])
            if meta_obj["root"].endswith("/" + meta_obj["name"]):
                target = "//{}".format(meta_obj["root"])
            all_cc_source_targets_map[target] = meta_obj["headers"]

    # Pretty-print the cc_source_targets dictionary to make
    # generated_constants.bzl easier to read.
    all_cc_source_targets_map_pp = "{\n"
    for k, v in all_cc_source_targets_map.items():
        all_cc_source_targets_map_pp += '  "{}": {},\n'.format(k, str(v))
    all_cc_source_targets_map_pp += "}\n"

    host_cpu_names = sorted(host_cpu_names_set.keys())
    target_cpu_names = sorted(target_cpu_names_set.keys())

    constants = runtime.make_struct(
        host_cpus = host_cpu_names,
        target_cpus = target_cpu_names,
    )
    generated_content = "# AUTO-GENERATED - DO NOT EDIT!\n\n"
    generated_content += '"""Fuchsia SDK constants."""\n'
    generated_content += (
        "# The following list of CPU names use Fuchsia conventions.\n"
    )
    generated_content += "constants = %s\n" % constants
    generated_content += "\n"
    generated_content += "# List of all c++ source targets in the SDK.\n"
    generated_content += (
        "ALL_CC_SOURCE_TARGETS = %s\n" % all_cc_source_targets_map_pp
    )

    repo_ctx.file(
        "generated_constants.bzl",
        generated_content,
        executable = False,
    )

    return constants

def _generate_sdk_build_rules(
        runtime,
        manifests,
        constants,
        filter_types = None,
        exclude_types = None):
    """Generates BUILD.bazel rules from the sdk metadata

    Args:
        runtime: A runtime value describing the current repository context and runtime environment.
        manifests: a list of paths to the meta data manifests.
        constants: A struct returned by generated_sdk_constants
        filter_types: tuple of sdk element types. If given, do not process any sdk element types that are not in this tuple
        exclude_types: tuple of sdk element types. If given, do not process any sdk element types in this tuple
    """
    ctx = runtime.ctx
    files_to_copy = (
        {}
    )  # key: sdk root path, value: list of files (string) relative to sdk
    dir_to_meta = {}
    parent_sdk_contents = {}
    _load_parent_sdk_metadata(runtime, parent_sdk_contents)
    for manifest_obj in manifests:
        root = manifest_obj.get("root")
        manifest_path = manifest_obj.get("manifest")
        json_obj = runtime.json_decode(
            ctx.read(_path_in_root(ctx, root, manifest_path)),
        )

        # Since all SDK manifests are in the same location, if we copy them all, they would clobber. So we only copy the first one and assume it is the main (core)
        files_to_copy[str(root)] = (
            [manifest_path] if len(files_to_copy) == 0 else []
        )

        # Collect all of the parts into a mapping for later templating. We need to
        # collect these here since we need to apply special logic to certain types
        # and cannot just generically apply templating to all types.
        for part in json_obj["parts"]:
            meta_file_rel = part["meta"]
            meta_file_with_root = _path_in_root(ctx, root, meta_file_rel)
            meta = runtime.json_decode(ctx.read(meta_file_with_root))
            t = _type_from_meta(runtime, meta)
            if (filter_types and t not in filter_types) or (
                exclude_types and t in exclude_types
            ):
                continue
            meta["_meta_path"] = meta_file_rel
            meta["_meta_sdk_root"] = str(root)
            if "root" in meta:
                dir = meta["root"]
            else:
                dir = meta_file_rel.rpartition("/")[0]

            # we need to group all meta files per root directory, but only process each file once
            if dir in dir_to_meta:
                dir_to_meta[dir][meta_file_rel] = meta
            else:
                dir_to_meta[dir] = {meta_file_rel: meta}

    def _expand_values(values):
        all_values = []
        for value in values:
            repo, rest = value.split("//", 1)
            if ":" in rest:
                pkg, target = rest.split(":", 1)
            else:
                pkg = rest
                target = rest.split("/")[-1]

            if target == "*":
                fail(
                    "When using wildcard expansion for visibility templates you " +
                    "must specify a target. Failing label is '{}'".format(value),
                )

            def _fmt_label(r, p, t):
                return "{}//{}:{}".format(r, p, t)

            # Check for wildcards and expand. This currently, only supports a
            # single "*" expansion.
            if "*" in pkg:
                if repo != "@@":
                    fail(
                        "Wildcard expansions are only supported in the main " +
                        "repository in fuchsia.git",
                    )
                left, rest = pkg.split("*", 1)
                directory = ctx.path(Label("@@//:BUILD.bazel")).dirname.get_child(left)
                if directory.exists:
                    for entry in directory.readdir():
                        # Check to see if the directory we are trying to add has a BUILD.bazel
                        # file and if it does add it here. We have to strip the leading "/" from
                        # the path we are appending or else bazel will think it is an absolute
                        # path and get_child will just return the new path and ignore entry.
                        if entry.get_child(rest.lstrip("/")).get_child("BUILD.bazel").exists:
                            all_values.append(_fmt_label(repo, left + entry.basename + rest, target))
            else:
                all_values.append(_fmt_label(repo, pkg, target))

        return all_values

    process_context = runtime.make_struct(
        files_to_copy = files_to_copy,
        component_manifest_targets = [],
        constants = constants,
        visibility_templates = {
            key: [Label(v) for v in _expand_values(values)]
            for key, values in ctx.attr.visibility_templates.items()
        },
    )

    for dir in dir_to_meta.keys():
        _process_dir(
            runtime,
            dir,
            dir_to_meta[dir].values(),
            process_context,
            parent_sdk_contents,
        )

    _write_cmc_includes(runtime, process_context)

    # Do not copy files from external repositories.
    # E.g. `@fuchsia_idk//arch/x64:dist/lib/libfoo.so`.
    files_to_copy = {
        root: [f for f in files if not _is_external_file(f)]
        for root, files in files_to_copy.items()
    }
    runtime.file_copier(files_to_copy)

def _ensure_build_id_file(runtime):
    ctx = runtime.ctx

    # BUILD.bazel references //:.build-id in a fuchsia_debug_symbol()
    # target declaration. This directory may not exist when the input
    # IDK is an external repository, so create an empty one if needed.
    if not ctx.path(".build-id").exists:
        ctx.file(".build-id/.empty-on-purpose")

def _export_all_files(runtime):
    ctx = runtime.ctx

    # Get a list of all BUILD.bazel files
    all_build_files = runtime.find_repository_files_by_name("BUILD.bazel")
    if not all_build_files:
        runtime.fail("Failed to enumerate all subpackages in @fuchsia_sdk")

    # Filter only the ones that expose `:_EXPORT_SUBPACKAGE_FILEGROUP`.
    # Transform "./<pkg>/BUILD.bazel" into "//<pkg>:_EXPORT_SUBPACKAGE_FILEGROUP`.
    EXPOSED_DEP = "_EXPORT_SUBPACKAGE_FILEGROUP"
    exported_targets = [
        "//%s:%s" % ("/".join(build_file.split("/")[1:-1]), EXPOSED_DEP)
        for build_file in all_build_files
        if EXPOSED_DEP in ctx.read(build_file)
    ]

    ctx.template(
        "BUILD.bazel",
        "BUILD.bazel",
        substitutions = {
            "{{ALL_FILES}}": _serialize(runtime, exported_targets),
        },
        executable = False,
    )

def generate_sdk_repository(runtime, manifests):
    """Populate the current repository directory.

    Args:
        runtime: A runtime value describing the current repository context and runtime environment.
        manifests: a list of dictionaries, each item describing a given input IDK with two keys:
            the "root" key, which has a string path value (absolute) pointing to an input IDK export
            directory, and the "manifest" key, which has a path string, relative to the root, pointing
            to the IDK manifest (which is typically just "meta/manifest.json").
    """
    constants = _generate_sdk_constants(runtime, manifests)

    ctx = runtime.ctx

    ctx.file("WORKSPACE.bazel", content = "", executable = False)
    ctx.report_progress("Generating Bazel rules for the SDK")
    ctx.template(
        "BUILD.bazel",
        runtime.label_to_path(_REPOSITORY_BUILD_TEMPLATE),
        substitutions = {
            "{{HOST_CPU}}": constants.host_cpus[0],
            "{{SDK_ID}}": _sdk_id_from_manifests(runtime, manifests),
        },
        executable = False,
    )

    # Generates all of the BUILD.bazel files and related content for the sdk
    _generate_sdk_build_rules(runtime, manifests, constants)

    # We need to make sure that there is a build id directory at the root
    _ensure_build_id_file(runtime)

    # Should only be called after all BUILD.bazel files have been added.
    _export_all_files(runtime)

    # Reformat / check formatting as the last step if needed.
    if runtime.run_buildifier:
        # First call with -lint=fix to automatically correct most issues.
        if not runtime.run_buildifier(["-mode=fix", "-lint=fix", "-r", "."]):
            runtime.fail("Error reformating Bazel SDK files!")

        # Second call with -lint=warn to verify that there aren't any remaining
        # issues that couldn't be fixed previously. This happens for warnings like
        # module-docstring, or bzl-visibility which require manual fixes.
        if not runtime.run_buildifier(["-mode=fix", "-lint=warn", "-r", "."]):
            runtime.fail("Bazel formatting errors persist in Bazel SDK files!")
